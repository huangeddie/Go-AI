{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "colab_type": "code",
    "id": "5YQ7bYMnwJRa",
    "outputId": "65617db9-e466-4ec7-d8e9-d829a89dc2a1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install tensorflow==2.0.0-beta1\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "# Restart the jupyter notebook if you just installed TF 2.0 Beta\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88zLHqvDwJRj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gym\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fc1lqGjPwJRm"
   },
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szyALIMpwJRo"
   },
   "source": [
    "# Go Environment\n",
    "Train on a small board with heuristic reward for fast training and efficient debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install -e gym-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4w7gMrfwJRp"
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size='S', reward_method='real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ju4HYnKwJRq"
   },
   "outputs": [],
   "source": [
    "BOARD_SIZE = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7ZoRfzIwJRr"
   },
   "source": [
    "# Machine Learning Models\n",
    "Deep Q Learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9wWb0HvwJRs"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dqn():\n",
    "    inputs = layers.Input(shape=(BOARD_SIZE, BOARD_SIZE, 4), name=\"board\")\n",
    "    valid_inputs = layers.Input(shape=(BOARD_SIZE**2 + 1,), name=\"valid_moves\")\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=1, kernel_size=1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    moves = layers.Dense(50, activation=\"tanh\")(x)\n",
    "    \n",
    "#     # Dense block\n",
    "#     num_layers = 8\n",
    "#     growth_rate = 4\n",
    "#     x = inputs\n",
    "#     for i in range(num_layers):\n",
    "#         y = tf.keras.Sequential([\n",
    "#             layers.Conv2D(filters=growth_rate, kernel_size=3, padding=\"same\", bias_initializer='ones'),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.ReLU(),\n",
    "#         ], name='dense_layer_{}'.format(i))(x)\n",
    "#         x = layers.Concatenate()([x,y])\n",
    "    \n",
    "#     moves = layers.Conv2D(filters=50, kernel_size=BOARD_SIZE, padding=\"valid\", name=\"all_moves\")(x)\n",
    "    \n",
    "#     moves = layers.Flatten()(moves)\n",
    "    \n",
    "    valid_moves = layers.Multiply(name='moves')([moves, valid_inputs])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs, valid_inputs], outputs=valid_moves, name='DQN')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dqn = make_dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DQN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "board (InputLayer)              [(None, 7, 7, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 7, 7, 64)     2368        board[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 64)     256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 7, 7, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     36928       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 64)     256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 64)     36928       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7, 7, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 64)     36928       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 7, 64)     256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 7, 7, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 1)      65          re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 1)      4           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 7, 7, 1)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 49)           0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           2500        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "valid_moves (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "moves (Multiply)                (None, 50)           0           dense[0][0]                      \n",
      "                                                                 valid_moves[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 116,745\n",
      "Trainable params: 116,231\n",
      "Non-trainable params: 514\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dqn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('tmp/dqn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent = tf.keras.models.clone_model(dqn)\n",
    "target_policy = tf.keras.models.clone_model(dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9djBWO1wJR1"
   },
   "source": [
    "### Initialization of models \n",
    "should be random if the models are fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(states, model):\n",
    "    invalid_moves = states[:,:,:,2].reshape((-1,49))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    valid_moves = 1 - invalid_moves\n",
    "    moves = model([states.astype(np.float32), valid_moves.astype(np.float32)])\n",
    "    return moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invalid_values(states):\n",
    "    \"\"\"\n",
    "    Returns the action values of the states where invalid moves have -infinity value (minimum value of float32)\n",
    "    and valid moves have 0 value\n",
    "    \"\"\"\n",
    "    invalid_moves = states[:,:,:,2].reshape((-1,49))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    invalid_values = np.finfo(np.float32).min * invalid_moves\n",
    "    return invalid_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_action_vals(states, q_network):\n",
    "    '''\n",
    "    The maximum action value (including passing) given the states\n",
    "    '''\n",
    "    invalid_values = get_invalid_values(states)\n",
    "    \n",
    "    move_vals = feed_forward(states, q_network)\n",
    "    max_vals = tf.reduce_max(move_vals + invalid_values, axis=1)\n",
    "    return max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_action_vals(states, q_network):\n",
    "    \"\"\"\n",
    "    Returns the moves that have the maximum values (including passing) given the states\n",
    "    \"\"\"\n",
    "    invalid_values = get_invalid_values(states)\n",
    "    \n",
    "    move_vals = feed_forward(states, q_network)\n",
    "    argmax_vals = tf.math.argmax(move_vals + invalid_values, axis=1)\n",
    "    \n",
    "    return argmax_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qH4rDyuowJR3",
    "outputId": "6376f7a8-99ff-4352-e6fc-0eccd05dfa25",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def state_responses(states, taken_actions=None, next_states=None, rewards=None, terminals=None):\n",
    "    \"\"\"\n",
    "    Returns a figure of plots on the states and the models responses on those states\n",
    "    \"\"\"\n",
    "    state_values = max_action_vals(states, dqn)\n",
    "    move_values = feed_forward(states, dqn)\n",
    "    \n",
    "    if next_states is not None:\n",
    "        next_move_values = feed_forward(next_states, dqn)\n",
    "        next_state_values = max_action_vals(next_states, dqn)\n",
    "    else:\n",
    "        next_move_values = None\n",
    "        next_state_values = None\n",
    "        \n",
    "    num_states = states.shape[0]\n",
    "    num_cols = 2 if next_states is None else 4\n",
    "    \n",
    "    fig = plt.figure(figsize=(num_cols * 3, num_states * 3))\n",
    "    for i in range(num_states):\n",
    "        plt.subplot(num_states,num_cols,1 + num_cols*i)\n",
    "        plt.axis('off')\n",
    "        plt.title('Board')\n",
    "        plt.imshow(states[i][:,:,[0,1,3]].astype(np.float))\n",
    "\n",
    "        plt.subplot(num_states,num_cols,2 + num_cols*i)\n",
    "        plt.axis('off')\n",
    "        plt.title('DQN {:.2f}S\\n{:.2f}L {:.2f}H {:.2f}P'\n",
    "                  .format(state_values[i], np.min(move_values[i][:-1]), \n",
    "                          np.max(move_values[i][:-1]), move_values[i][-1]))\n",
    "        plt.imshow(tf.reshape(move_values[i][:-1], (BOARD_SIZE, BOARD_SIZE)))\n",
    "        \n",
    "        if next_states is not None:\n",
    "            assert taken_actions is not None and len(taken_actions) == len(next_states)\n",
    "            if i < next_states.shape[0]:\n",
    "                plt.subplot(num_states,num_cols, 3 + num_cols*i)\n",
    "                plt.axis('off')\n",
    "                plt.title('Taken Action: {}\\n{:.0f}R {}T'.format(taken_actions[i], rewards[i], terminals[i]))\n",
    "                plt.imshow(next_states[i][:,:,[0,1,3]].astype(np.float))\n",
    "                \n",
    "                plt.subplot(num_states,num_cols,4 + num_cols*i)\n",
    "                plt.axis('off')\n",
    "                plt.title('DQN {:.2f}S\\n{:.2f}L {:.2f}H {:.2f}P'\n",
    "                          .format(next_state_values[i], np.min(next_move_values[i][:-1]), \n",
    "                                  np.max(next_move_values[i][:-1]), next_move_values[i][-1]))\n",
    "                plt.imshow(tf.reshape(next_move_values[i][:-1], (BOARD_SIZE, BOARD_SIZE)))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98jmZoKvwJRv"
   },
   "outputs": [],
   "source": [
    "state = go_env.reset()\n",
    "start_state = np.copy(state)\n",
    "state, reward, done, info = go_env.step((3,5))\n",
    "state, reward, done, info = go_env.step((5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJWxThQMwJRz"
   },
   "outputs": [],
   "source": [
    "states = state.transpose(1,2,0).reshape(1, BOARD_SIZE, BOARD_SIZE, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(state_responses(states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViUxxPnUwJR5"
   },
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfY-_1_5wJR5"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DX04C6TbwJR5"
   },
   "outputs": [],
   "source": [
    "NUM_EPISODES = 2000\n",
    "BATCH_SIZE = 256\n",
    "MAX_STEPS = 2 * BOARD_SIZE**2\n",
    "REPLAY_MEM_SIZE = 1e4\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "OPPONENT_UPDATE = 200\n",
    "\n",
    "EPSILON = 1\n",
    "EPSILON_DECAY = 0.95\n",
    "EPSILON_MIN = 0.1\n",
    "\n",
    "GAMMA = 0.90\n",
    "TARGET_UPDATE = 1 # number of episodes to update the target critic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([GAMMA**x for x in range(100)])\n",
    "plt.title(\"Gamma Powers\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sumB3IsFwJR6"
   },
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MeB26mZvwJR7"
   },
   "outputs": [],
   "source": [
    "replay_mem = deque(maxlen=int(REPLAY_MEM_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for metric_key in ['loss', 'win_percentage']:\n",
    "    metrics[metric_key] = tf.keras.metrics.Mean('dqn_{}'.format(metric_key), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writers = {}\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "for summary_key in ['train', 'test']:\n",
    "    log_dir = 'logs/dqn/{}/{}'.format(current_time, summary_key)\n",
    "    summary_writers[summary_key] = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXOIVFjmwJR7"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_1d_to_2d(action_1d):\n",
    "    if action_1d == BOARD_SIZE**2:\n",
    "        action = None\n",
    "    else:\n",
    "        action = (action_1d // BOARD_SIZE, action_1d % BOARD_SIZE)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weighted_action(move_weights):\n",
    "    \"\"\"\n",
    "    Assumes all invalid moves have weight 0\n",
    "    \"\"\"\n",
    "    move_weights = preprocessing.normalize(move_weights, norm='l1')\n",
    "\n",
    "    if np.sum(move_weights) <= 0:\n",
    "        # Pass\n",
    "        return None\n",
    "    \n",
    "    action_1d = np.random.choice(np.arange(BOARD_SIZE**2 + 1), p=move_weights[0])\n",
    "    return convert_1d_to_2d(action_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(state):\n",
    "    \"\"\"\n",
    "    Assumed to be (BOARD_SIZE, BOARD_SIZE, 4)\n",
    "    \"\"\"\n",
    "    invalid_moves = state[:,:,2].reshape((1,-1))\n",
    "    invalid_moves = np.insert(invalid_moves, BOARD_SIZE**2, 0, axis=1)\n",
    "    move_weights = 1 - invalid_moves\n",
    "\n",
    "    action = random_weighted_action(move_weights)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(policy, state, epsilon):\n",
    "    \"\"\"\n",
    "    Gets an action based on exploration/exploitation\n",
    "    \"\"\"\n",
    "    if state.shape[0] == 4:\n",
    "        # State shape will be (BOARD_SIZE, BOARD_SIZE, 4)\n",
    "        state = state.transpose(1,2,0)\n",
    "            \n",
    "    epsilon_choice = np.random.uniform()\n",
    "    if epsilon_choice < epsilon:\n",
    "        # Random move\n",
    "        logging.debug(\"Exploring a random move\")\n",
    "        action = random_action(state)\n",
    "        \n",
    "    else:\n",
    "        # policy makes a move\n",
    "        logging.debug(\"Exploiting policy's move\")\n",
    "        reshaped_state = state.reshape(1, BOARD_SIZE, BOARD_SIZE, 4).astype(np.float32)\n",
    "        \n",
    "        flattened_actions = argmax_action_vals(reshaped_state, policy)\n",
    "        action_1d = flattened_actions[0].numpy()\n",
    "        action = convert_1d_to_2d(action_1d)\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_for_action(move_values, actions):\n",
    "    '''\n",
    "    Get value from board_values based on action, or take the passing_values if the action is None\n",
    "    '''\n",
    "    action_values = tf.gather_nd(move_values, [(i, a[0] * BOARD_SIZE + a[1]) if a is not None \n",
    "                                                    else (i, BOARD_SIZE**2) \n",
    "                                                    for i, a in enumerate(actions)])\n",
    "    return action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_obs(size=BATCH_SIZE):\n",
    "    '''\n",
    "    Get a batch of orig_states, actions, states, rewards, terminals as np array out of replay memory\n",
    "    '''\n",
    "    \n",
    "    # States were (BATCH_SIZE, 4, BOARD_SIZE, BOARD_SIZE)\n",
    "    # Convert them to (BATCH_SIZE, BOARD_SIZE, BOARD_SIZE, 4)\n",
    "    batch = random.sample(replay_mem, size)\n",
    "    batch = list(zip(*batch))\n",
    "    orig_states = np.array(list(batch[0]), dtype=np.float32).transpose(0,2,3,1)\n",
    "    actions = list(batch[1])\n",
    "    states = np.array(list(batch[2]), dtype=np.float32).transpose(0,2,3,1)\n",
    "    rewards = np.array(list(batch[3]), dtype=np.float32)\n",
    "    terminals = np.array(list(batch[4]), dtype=np.uint8)\n",
    "    \n",
    "    return orig_states, actions, states, rewards, terminals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_heatmaps():\n",
    "    num_samples = 2\n",
    "    states, actions, next_states, rewards, terminals = get_batch_obs(num_samples)\n",
    "    # Add a random terminal state\n",
    "    random.shuffle(replay_mem)\n",
    "    for (state, action, next_state, reward, terminal) in replay_mem:\n",
    "        if terminal:\n",
    "            states = np.concatenate([states, state.transpose(1,2,0)\n",
    "                             .reshape((-1,BOARD_SIZE, BOARD_SIZE, 4))], axis=0)\n",
    "            actions.append(action)\n",
    "            next_states = np.concatenate([next_states, next_state.transpose(1,2,0)\n",
    "                             .reshape((-1,BOARD_SIZE, BOARD_SIZE, 4))], axis=0)\n",
    "            rewards = np.append(rewards, reward)\n",
    "            terminals = np.append(terminals, terminal)\n",
    "            break\n",
    "    # Add start state\n",
    "    states = np.concatenate([states, start_state.transpose(1,2,0)\n",
    "                             .reshape((-1,BOARD_SIZE, BOARD_SIZE, 4))], axis=0)\n",
    "    fig = state_responses(states, actions, next_states, rewards, terminals)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8QseVrawJR8"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "def update_dqn():\n",
    "    \"\"\"\n",
    "    Optimizes the critic in one step and updates the critic loss metric\n",
    "    \"\"\"\n",
    "    states, actions, next_states, rewards, terminals = get_batch_obs()\n",
    "    \n",
    "    # get values for next state\n",
    "    next_state_vals = max_action_vals(next_states, target_policy)\n",
    "    \n",
    "    batch_size = states.shape[0]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        move_vals = feed_forward(states, dqn)\n",
    "        action_vals = get_value_for_action(move_vals, actions)\n",
    "        val_loss = mean_squared_error(rewards + GAMMA * next_state_vals * (1-terminals), action_vals)\n",
    "    \n",
    "    metrics['loss'](val_loss)\n",
    "    \n",
    "    # compute and apply gradients\n",
    "    gradients = tape.gradient(val_loss, dqn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, dqn.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0E04emPwJR-"
   },
   "outputs": [],
   "source": [
    "def play_a_game(episode, train, black_epsilon, white_epsilon):\n",
    "    \"\"\"\n",
    "    Plays out a game, and iteratively updates the models at each step\n",
    "    Returns the number of moves by the end of the game and the list \n",
    "    of rewards after every turn by the black player\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic setup\n",
    "    done = False\n",
    "    num_steps = 0\n",
    "    state = go_env.reset()\n",
    "    win = None\n",
    "    \n",
    "    while True:\n",
    "        # Copy state for memory\n",
    "        orig_state = np.copy(state)\n",
    "        \n",
    "        black_action = get_action(dqn, state, epsilon=black_epsilon)\n",
    "        if black_action is None:\n",
    "            logging.debug(\"Black (actor) passed\")\n",
    "            \n",
    "        state, reward, done, info = go_env.step(black_action)\n",
    "        num_steps += 1\n",
    "        \n",
    "        # Update the critic and then actor if we are training and have enough events\n",
    "        if train and len(replay_mem) >= BATCH_SIZE:\n",
    "            update_dqn()        \n",
    "            \n",
    "        if num_steps > MAX_STEPS:\n",
    "            # Max number of steps. End game\n",
    "            reward = 1 if info['area']['b'] > info['area']['w'] else -1\n",
    "            done = True\n",
    "        if done:\n",
    "            # Set the winner if we're done\n",
    "            win = reward\n",
    "            if train:\n",
    "                # Add to memory if training \n",
    "                # (black ended the game by making the last pass OR we hit the max number of steps)\n",
    "                replay_mem.append((orig_state, black_action, np.copy(state), reward, done))\n",
    "            break\n",
    "            \n",
    "        # opponent makes a move\n",
    "        # swap the black and white layers\n",
    "        temp = np.copy(state[0])\n",
    "        state[0] = state[1]\n",
    "        state[1] = temp\n",
    "        # get action from opponent\n",
    "        white_action = get_action(None, state, epsilon=white_epsilon)\n",
    "        if white_action is None:\n",
    "            logging.debug(\"White (opponent) passed\")\n",
    "\n",
    "        state, reward, done, info = go_env.step(white_action)\n",
    "        num_steps += 1\n",
    "        \n",
    "        \n",
    "        if num_steps > MAX_STEPS:\n",
    "            # Max number of steps. End game\n",
    "            reward = 1 if info['area']['b'] > info['area']['w'] else -1\n",
    "            done = True\n",
    "        if train:\n",
    "            # Add to memory if training\n",
    "            replay_mem.append((orig_state, black_action, np.copy(state), reward, done))\n",
    "        if done:\n",
    "            # Set the winner if we're done\n",
    "            win = reward\n",
    "            break\n",
    "    \n",
    "    # Game ended\n",
    "    return num_steps, win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNBj_gKPwJR_"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LT1PUXyXwJR_",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py(801)__exit__()\n",
      "-> def __exit__(self, typ, value, traceback):\n",
      "(Pdb) u\n",
      "> <ipython-input-50-ea10f57bc4fc>(17)update_dqn()\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) u\n",
      "> <ipython-input-45-78c3705a4638>(27)play_a_game()\n",
      "-> update_dqn()\n",
      "(Pdb) d\n",
      "> <ipython-input-50-ea10f57bc4fc>(17)update_dqn()\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) list\n",
      " 12  \t\n",
      " 13  \t    with tf.GradientTape() as tape:\n",
      " 14  \t        move_vals = feed_forward(states, dqn)\n",
      " 15  \t        action_vals = get_value_for_action(move_vals, actions)\n",
      " 16  \t        val_loss = mean_squared_error(rewards + GAMMA * next_state_vals * (1-terminals), action_vals) / batch_size\n",
      " 17  ->\t        import pdb; pdb.set_trace()\n",
      " 18  \t\n",
      " 19  \t    metrics['loss'](val_loss)\n",
      " 20  \t\n",
      " 21  \t    # compute and apply gradients\n",
      " 22  \t    gradients = tape.gradient(val_loss, dqn.trainable_variables)\n",
      "(Pdb) move_vals\n",
      "<tf.Tensor: id=54301135, shape=(256, 50), dtype=float32, numpy=\n",
      "array([[ 0.21793061,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.22725512,  0.12374815],\n",
      "       [ 0.07070697,  0.08869778,  0.09912282, ...,  0.06524863,\n",
      "         0.04960253, -0.08221054],\n",
      "       [-0.        , -0.        , -0.        , ..., -0.        ,\n",
      "        -0.        , -0.7169267 ],\n",
      "       ...,\n",
      "       [ 0.22334121,  0.23418699,  0.24919163, ...,  0.23802164,\n",
      "         0.23374826,  0.13142733],\n",
      "       [ 0.12367469,  0.13922825,  0.15133838, ...,  0.12534519,\n",
      "         0.11363905, -0.00898504],\n",
      "       [-0.        ,  0.        ,  0.        , ..., -0.        ,\n",
      "        -0.        , -0.19220416]], dtype=float32)>\n",
      "(Pdb) action_vals\n",
      "<tf.Tensor: id=54301137, shape=(256,), dtype=float32, numpy=\n",
      "array([ 0.23295464,  0.10608769, -0.46541274,  0.26060253, -0.32633367,\n",
      "       -0.6475986 ,  0.5910448 ,  0.11418604,  0.26244617, -0.02286929,\n",
      "        0.2118556 , -0.12185896,  0.41840294,  0.3938954 ,  0.2297037 ,\n",
      "       -0.02730406,  0.08402704,  0.28200564,  0.33315122, -0.67885226,\n",
      "        0.7317909 , -0.07371216, -0.14102231,  0.4067698 ,  0.04795732,\n",
      "        0.11669201,  0.1936084 ,  0.13636684,  0.06217175,  0.14931016,\n",
      "        0.06281142,  0.2339678 , -0.05838505,  0.04984601,  0.07038534,\n",
      "        0.28784567, -0.04144522,  0.11114073,  0.14275236,  0.18047272,\n",
      "        0.10000715,  0.06739979,  0.1698161 ,  0.14109714,  0.09591134,\n",
      "        0.1081852 ,  0.04533168,  0.19616799,  0.20671469,  0.03058474,\n",
      "        0.24434859,  0.11394002,  0.10442688,  0.10105338,  0.35625055,\n",
      "        0.22163105,  0.2719112 ,  0.25719017,  0.22086684,  0.22881521,\n",
      "        0.88382196,  0.6891453 ,  0.37761632,  0.24514532,  0.10000715,\n",
      "        0.31034687,  0.14573228,  0.12584214,  0.40604457, -0.63479656,\n",
      "        0.7486172 ,  0.19084652,  0.9792808 ,  0.32455644, -0.21701027,\n",
      "       -0.23970622,  0.44861   ,  0.51514345,  0.13181005,  0.03426949,\n",
      "        0.14338306,  0.2715096 ,  0.23072794,  0.4219157 ,  0.10000715,\n",
      "        0.3383448 ,  0.2092072 ,  0.09344002,  0.31606853,  0.14982393,\n",
      "        0.07722609,  0.02746969,  0.12255901,  0.16333549,  0.75910854,\n",
      "        0.20866829, -0.23018621,  0.12090125,  0.02099658,  0.1389044 ,\n",
      "        0.5537278 , -0.11159476,  0.0725361 ,  0.05862212,  0.1595547 ,\n",
      "        0.10128079,  0.10000715,  0.3035915 , -0.6998949 ,  0.31854323,\n",
      "       -0.5579241 ,  0.10000715,  0.04525905,  0.18279605,  0.2055119 ,\n",
      "        0.09477544,  0.25849822,  0.11229356, -0.635322  ,  0.08568389,\n",
      "        0.16330034,  0.06114623,  0.10631229,  0.24123226, -0.50519204,\n",
      "        0.18502639, -0.04045036,  0.7845045 ,  0.10568575,  0.51881135,\n",
      "        0.41706327,  0.06021246,  0.31350344,  0.12437628,  0.15398037,\n",
      "       -0.10831697, -0.08891114,  0.5918618 , -0.06225641,  0.52160215,\n",
      "        0.15682435,  0.6288321 ,  0.4590724 ,  0.60177547,  0.19915052,\n",
      "        0.30626777,  0.14295077,  0.01749546,  0.14191128,  0.20542707,\n",
      "        0.6266827 , -0.26351306,  0.22158474,  0.08066748,  0.32778478,\n",
      "       -0.31648865,  0.09263984,  0.61653435,  0.8317993 , -0.00828223,\n",
      "        0.18488385,  0.0563149 ,  0.31650558,  0.20795296,  0.34676674,\n",
      "        0.33065513,  0.08196799,  0.0458598 ,  0.37285402,  0.10000715,\n",
      "        0.7791079 ,  0.14574409,  0.3486369 ,  0.84818715,  0.09182902,\n",
      "        0.2716144 ,  0.29279736,  0.18656969,  0.10763599,  0.11009015,\n",
      "        0.48458344, -0.34799019,  0.18616061,  0.22957641,  0.16812934,\n",
      "        0.20661838,  0.2754627 ,  0.10000715,  0.16424178,  0.18368614,\n",
      "        0.10000715,  0.45225152,  0.00945474,  0.49740228,  0.08319149,\n",
      "        0.7551312 ,  0.0759977 ,  0.01708341,  0.02817046,  0.15524852,\n",
      "        0.41551378,  0.40340656,  0.00582408,  0.2573705 ,  0.02015014,\n",
      "       -0.16783549,  0.24241413,  0.42914724,  0.7295795 , -0.40665108,\n",
      "        0.44181624, -0.01237961,  0.11114073,  0.11426694,  0.1389044 ,\n",
      "        0.14136656,  0.25572523,  0.06267232,  0.10349742,  0.10000715,\n",
      "        0.1262674 ,  0.21485281,  0.14941177,  0.03378845, -0.02794128,\n",
      "        0.26520923,  0.53582925,  0.1740362 ,  0.09895421,  0.10442688,\n",
      "        0.36441627,  0.12018258,  0.02827409,  0.16703796,  0.19863655,\n",
      "        0.2032674 , -0.64464444,  0.11076666, -0.54441714,  0.28500444,\n",
      "        0.15682478,  0.35057887,  0.10565145,  0.22699451,  0.23064895,\n",
      "        0.09931091,  0.16227551,  0.25793806, -0.6221912 ,  0.26155528,\n",
      "        0.01998373,  0.12588309,  0.1821653 ,  0.2569547 ,  0.13935293,\n",
      "       -0.03541103], dtype=float32)>\n",
      "(Pdb) rewards\n",
      "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)\n",
      "(Pdb) next_state_vals\n",
      "<tf.Tensor: id=54301025, shape=(256,), dtype=float32, numpy=\n",
      "array([ 0.23050576,  0.12250264, -0.3828313 ,  0.2941116 , -0.33457607,\n",
      "       -0.69679815,  0.6224445 ,  0.12645856,  0.26608178,  0.11687327,\n",
      "        0.25308573, -0.11678644,  0.37760824,  0.46600822,  0.23399007,\n",
      "       -0.03698985,  0.10793437,  0.23887256,  0.35238287, -0.43740344,\n",
      "        0.9760378 ,  0.08416808,  0.02739137,  0.6147751 ,  0.04618188,\n",
      "        0.11220594,  0.27489814,  0.12893075,  0.0336814 ,  0.18606417,\n",
      "        0.07003119,  0.34272784, -0.10556169,  0.00727748,  0.07591152,\n",
      "        0.3951094 , -0.03693086,  0.12250264,  0.21194741,  0.15116785,\n",
      "        0.09719997,  0.0209345 ,  0.15931676,  0.13337903,  0.27615902,\n",
      "        0.13213831, -0.06391723,  0.73476845,  0.2635873 ,  0.12060349,\n",
      "        0.3040588 ,  0.17838517,  0.11697239,  0.15899613,  0.31529674,\n",
      "        0.22999397,  0.25264126,  0.2601701 ,  0.4166668 ,  0.2648721 ,\n",
      "        0.89586294,  0.7805606 ,  0.5101234 ,  0.35566008,  0.08636239,\n",
      "        0.30409992,  0.24964944,  0.17538553,  0.39135894, -0.6471893 ,\n",
      "        0.7885148 ,  0.27348912,  0.9759052 ,  0.33030516, -0.28636527,\n",
      "       -0.29281673,  0.26754764,  0.70433193,  0.13967548,  0.04385904,\n",
      "        0.10153128,  0.28604272,  0.22841956,  0.47920236,  0.09765828,\n",
      "        0.42751977,  0.19711432,  0.10276666,  0.33761287,  0.16384585,\n",
      "       -0.05144503, -0.01237961,  0.17659593,  0.30550277,  0.796463  ,\n",
      "        0.24067758, -0.20338792,  0.12176865,  0.0171141 ,  0.13585922,\n",
      "        0.5885045 , -0.09802683,  0.07848893, -0.0816494 ,  0.20130375,\n",
      "        0.10983913,  0.11114073,  0.2840434 ,  0.11277962,  0.25613752,\n",
      "       -0.6109262 ,  0.11114073, -0.02045441,  0.22512768,  0.27810144,\n",
      "        0.10799417,  0.2106111 ,  0.12327602, -0.6361068 ,  0.07947752,\n",
      "        0.14710501,  0.06829491,  0.13890988,  0.19422576, -0.5061058 ,\n",
      "        0.13469967,  0.05053426,  0.81399107,  0.13011873,  0.5902432 ,\n",
      "        0.43206176,  0.0148118 ,  0.3808183 ,  0.17026585,  0.1518533 ,\n",
      "       -0.00304138, -0.0792136 ,  0.63589835,  0.03364198,  0.5080368 ,\n",
      "        0.16208492,  0.90688854,  0.6120117 ,  0.69681776,  0.22937681,\n",
      "        0.3569344 ,  0.08476935,  0.02276116,  0.15444507,  0.18286437,\n",
      "        0.6360699 , -0.84461784,  0.23091829,  0.0663866 ,  0.435016  ,\n",
      "       -0.35917854,  0.02872469,  0.6186763 ,  0.9312322 ,  0.12769549,\n",
      "        0.18515372,  0.11487028,  0.27027696,  0.23710464,  0.23304734,\n",
      "        0.38006693, -0.07270975,  0.07687137,  0.39784417,  0.11114073,\n",
      "        0.8696184 ,  0.19699119,  0.34342486,  0.84818715,  0.12892939,\n",
      "        0.3287099 ,  0.3470046 ,  0.1906978 ,  0.1431305 ,  0.12692723,\n",
      "        0.53735846, -0.10882247,  0.17597781,  0.24897057,  0.12987736,\n",
      "        0.28401664,  0.30834618,  0.11114073,  0.24263798, -0.07236736,\n",
      "        0.08846419,  0.6397083 ,  0.14421232,  0.432384  ,  0.05526746,\n",
      "        0.59568715,  0.08846419,  0.01608787, -0.00820535,  0.22095393,\n",
      "        0.46819636,  0.58864   , -0.00347792,  0.26087725,  0.21393953,\n",
      "       -0.12823752,  0.23908816,  0.6287278 ,  0.7224016 , -0.39879715,\n",
      "        0.543859  , -0.02222565,  0.13045873,  0.12183721,  0.13585922,\n",
      "        0.16281354,  0.21689633,  0.13776696,  0.11156398,  0.11114073,\n",
      "        0.1352427 ,  0.3043722 ,  0.12622277,  0.04085233, -0.1369734 ,\n",
      "        0.2721827 ,  0.69104266,  0.20010476,  0.1868717 ,  0.15504435,\n",
      "        0.31470078,  0.12503964,  0.03400766,  0.3142663 ,  0.09948649,\n",
      "        0.314901  , -0.6361068 ,  0.15752475, -0.61473405,  0.31245297,\n",
      "        0.19799614,  0.4042505 ,  0.11690419,  0.2126405 ,  0.22409211,\n",
      "        0.08300225,  0.16893809,  0.8213299 , -0.6397691 ,  0.22361523,\n",
      "       -0.05994343,  0.12043051,  0.18421495,  0.2458927 ,  0.12131235,\n",
      "        0.1012185 ], dtype=float32)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) terminals\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)\n",
      "(Pdb) 1 - terminals\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=uint8)\n",
      "(Pdb) list\n",
      " 23  \t    optimizer.apply_gradients(zip(gradients, dqn.trainable_variables))\n",
      "[EOF]\n",
      "(Pdb) list 0\n",
      "  1  \toptimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
      "  2  \tdef update_dqn():\n",
      "  3  \t    \"\"\"\n",
      "  4  \t    Optimizes the critic in one step and updates the critic loss metric\n",
      "  5  \t    \"\"\"\n",
      "  6  \t    states, actions, next_states, rewards, terminals = get_batch_obs()\n",
      "  7  \t\n",
      "  8  \t    # get values for next state\n",
      "  9  \t    next_state_vals = max_action_vals(next_states, target_policy)\n",
      " 10  \t\n",
      " 11  \t    batch_size = states.shape[0]\n",
      "(Pdb) list 20\n",
      " 15  \t        action_vals = get_value_for_action(move_vals, actions)\n",
      " 16  \t        val_loss = mean_squared_error(rewards + GAMMA * next_state_vals * (1-terminals), action_vals) / batch_size\n",
      " 17  ->\t        import pdb; pdb.set_trace()\n",
      " 18  \t\n",
      " 19  \t    metrics['loss'](val_loss)\n",
      " 20  \t\n",
      " 21  \t    # compute and apply gradients\n",
      " 22  \t    gradients = tape.gradient(val_loss, dqn.trainable_variables)\n",
      " 23  \t    optimizer.apply_gradients(zip(gradients, dqn.trainable_variables))\n",
      "[EOF]\n",
      "(Pdb) list 17\n",
      " 12  \t\n",
      " 13  \t    with tf.GradientTape() as tape:\n",
      " 14  \t        move_vals = feed_forward(states, dqn)\n",
      " 15  \t        action_vals = get_value_for_action(move_vals, actions)\n",
      " 16  \t        val_loss = mean_squared_error(rewards + GAMMA * next_state_vals * (1-terminals), action_vals) / batch_size\n",
      " 17  ->\t        import pdb; pdb.set_trace()\n",
      " 18  \t\n",
      " 19  \t    metrics['loss'](val_loss)\n",
      " 20  \t\n",
      " 21  \t    # compute and apply gradients\n",
      " 22  \t    gradients = tape.gradient(val_loss, dqn.trainable_variables)\n",
      "(Pdb) batch_size\n",
      "256\n",
      "(Pdb) GAMMA * next_state_vals\n",
      "<tf.Tensor: id=54301157, shape=(256,), dtype=float32, numpy=\n",
      "array([ 0.20745519,  0.11025237, -0.34454817,  0.26470044, -0.30111846,\n",
      "       -0.6271183 ,  0.56020004,  0.1138127 ,  0.2394736 ,  0.10518594,\n",
      "        0.22777715, -0.1051078 ,  0.33984742,  0.4194074 ,  0.21059106,\n",
      "       -0.03329086,  0.09714093,  0.2149853 ,  0.31714457, -0.39366308,\n",
      "        0.878434  ,  0.07575127,  0.02465224,  0.5532976 ,  0.04156369,\n",
      "        0.10098534,  0.24740832,  0.11603767,  0.03031326,  0.16745774,\n",
      "        0.06302807,  0.30845505, -0.09500552,  0.00654973,  0.06832037,\n",
      "        0.35559845, -0.03323777,  0.11025237,  0.19075267,  0.13605106,\n",
      "        0.08747997,  0.01884105,  0.14338508,  0.12004112,  0.24854311,\n",
      "        0.11892448, -0.0575255 ,  0.6612916 ,  0.23722856,  0.10854314,\n",
      "        0.2736529 ,  0.16054665,  0.10527515,  0.14309652,  0.28376704,\n",
      "        0.20699456,  0.22737713,  0.23415309,  0.37500012,  0.23838489,\n",
      "        0.8062766 ,  0.7025045 ,  0.45911103,  0.32009408,  0.07772615,\n",
      "        0.27368993,  0.22468449,  0.15784697,  0.35222304, -0.58247036,\n",
      "        0.7096633 ,  0.2461402 ,  0.8783146 ,  0.29727465, -0.25772873,\n",
      "       -0.26353505,  0.24079287,  0.63389874,  0.12570792,  0.03947314,\n",
      "        0.09137815,  0.25743845,  0.2055776 ,  0.4312821 ,  0.08789245,\n",
      "        0.38476777,  0.17740288,  0.09249   ,  0.30385157,  0.14746127,\n",
      "       -0.04630053, -0.01114165,  0.15893634,  0.2749525 ,  0.71681666,\n",
      "        0.21660982, -0.18304911,  0.10959178,  0.01540269,  0.1222733 ,\n",
      "        0.529654  , -0.08822415,  0.07064003, -0.07348446,  0.18117337,\n",
      "        0.09885521,  0.10002665,  0.25563905,  0.10150166,  0.23052377,\n",
      "       -0.5498336 ,  0.10002665, -0.01840897,  0.2026149 ,  0.2502913 ,\n",
      "        0.09719475,  0.18954998,  0.11094841, -0.5724961 ,  0.07152977,\n",
      "        0.13239451,  0.06146542,  0.12501888,  0.17480318, -0.45549518,\n",
      "        0.1212297 ,  0.04548083,  0.7325919 ,  0.11710685,  0.5312189 ,\n",
      "        0.38885558,  0.01333062,  0.34273645,  0.15323927,  0.13666797,\n",
      "       -0.00273724, -0.07129224,  0.5723085 ,  0.03027778,  0.4572331 ,\n",
      "        0.14587642,  0.81619966,  0.5508105 ,  0.627136  ,  0.20643912,\n",
      "        0.32124096,  0.07629241,  0.02048505,  0.13900055,  0.16457793,\n",
      "        0.5724629 , -0.76015604,  0.20782645,  0.05974793,  0.3915144 ,\n",
      "       -0.3232607 ,  0.02585222,  0.55680865,  0.83810896,  0.11492594,\n",
      "        0.16663834,  0.10338325,  0.24324927,  0.21339417,  0.20974259,\n",
      "        0.34206024, -0.06543878,  0.06918423,  0.35805973,  0.10002665,\n",
      "        0.78265655,  0.17729206,  0.30908236,  0.7633684 ,  0.11603645,\n",
      "        0.2958389 ,  0.31230414,  0.17162801,  0.12881744,  0.1142345 ,\n",
      "        0.4836226 , -0.09794022,  0.15838003,  0.2240735 ,  0.11688962,\n",
      "        0.25561497,  0.27751157,  0.10002665,  0.21837418, -0.06513062,\n",
      "        0.07961777,  0.5757374 ,  0.12979108,  0.3891456 ,  0.04974072,\n",
      "        0.53611845,  0.07961777,  0.01447908, -0.00738481,  0.19885853,\n",
      "        0.4213767 ,  0.529776  , -0.00313013,  0.23478952,  0.19254558,\n",
      "       -0.11541376,  0.21517934,  0.565855  ,  0.65016145, -0.35891742,\n",
      "        0.4894731 , -0.02000309,  0.11741285,  0.10965349,  0.1222733 ,\n",
      "        0.1465322 ,  0.19520669,  0.12399026,  0.10040758,  0.10002665,\n",
      "        0.12171843,  0.27393496,  0.11360049,  0.03676709, -0.12327605,\n",
      "        0.24496442,  0.6219384 ,  0.18009427,  0.16818453,  0.13953991,\n",
      "        0.2832307 ,  0.11253567,  0.03060689,  0.28283966,  0.08953784,\n",
      "        0.28341088, -0.5724961 ,  0.14177227, -0.5532606 ,  0.28120768,\n",
      "        0.17819652,  0.36382544,  0.10521377,  0.19137643,  0.2016829 ,\n",
      "        0.07470202,  0.15204427,  0.7391969 , -0.57579213,  0.2012537 ,\n",
      "       -0.05394908,  0.10838746,  0.16579345,  0.22130343,  0.10918111,\n",
      "        0.09109665], dtype=float32)>\n",
      "(Pdb) (GAMMA * next_state_vals - action_vals) ** 2\n",
      "<tf.Tensor: id=54301163, shape=(256,), dtype=float32, numpy=\n",
      "array([6.50221831e-04, 1.73445660e-05, 1.46082444e-02, 1.67928556e-05,\n",
      "       6.35806762e-04, 4.19444114e-04, 9.51398455e-04, 1.39383616e-07,\n",
      "       5.27738943e-04, 1.63981412e-02, 2.53495702e-04, 2.80601438e-04,\n",
      "       6.17097039e-03, 6.50862639e-04, 3.65292683e-04, 3.58417783e-05,\n",
      "       1.71974010e-04, 4.49172640e-03, 2.56212807e-04, 8.13328698e-02,\n",
      "       2.15041991e-02, 2.23393161e-02, 2.74480525e-02, 2.14703865e-02,\n",
      "       4.08784581e-05, 2.46699579e-04, 2.89443065e-03, 4.13275440e-04,\n",
      "       1.01496326e-03, 3.29334929e-04, 4.69363499e-08, 5.54835098e-03,\n",
      "       1.34105899e-03, 1.87456759e-03, 4.26408315e-06, 4.59043914e-03,\n",
      "       6.73621398e-05, 7.89174749e-07, 2.30402942e-03, 1.97328371e-03,\n",
      "       1.56930124e-04, 2.35795137e-03, 6.98599033e-04, 4.43355937e-04,\n",
      "       2.32964586e-02, 1.15332012e-04, 1.05796009e-02, 2.16339961e-01,\n",
      "       9.31096147e-04, 6.07751170e-03, 8.58743500e-04, 2.17217719e-03,\n",
      "       7.19563616e-07, 1.76762580e-03, 5.25385933e-03, 2.14226748e-04,\n",
      "       1.98328355e-03, 5.30706893e-04, 2.37570666e-02, 9.15786732e-05,\n",
      "       6.01328071e-03, 1.78467933e-04, 6.64138934e-03, 5.61731635e-03,\n",
      "       4.96442895e-04, 1.34373165e-03, 6.23345096e-03, 1.02430931e-03,\n",
      "       2.89675756e-03, 2.73803156e-03, 1.51740632e-03, 3.05739092e-03,\n",
      "       1.01941768e-02, 7.44296121e-04, 1.65799225e-03, 5.67813346e-04,\n",
      "       4.31879610e-02, 1.41028166e-02, 3.72359900e-05, 2.70778892e-05,\n",
      "       2.70451000e-03, 1.97996895e-04, 6.32539799e-04, 8.77293205e-05,\n",
      "       1.46765859e-04, 2.15509115e-03, 1.01151492e-03, 9.02544684e-07,\n",
      "       1.49254003e-04, 5.58220245e-06, 1.52588254e-02, 1.49083568e-03,\n",
      "       1.32330984e-03, 1.24583580e-02, 1.78860314e-03, 6.30678842e-05,\n",
      "       2.22190586e-03, 1.27904044e-04, 3.12916600e-05, 2.76593375e-04,\n",
      "       5.79546846e-04, 5.46185358e-04, 3.59507567e-06, 1.74521469e-02,\n",
      "       4.67366655e-04, 5.88344437e-06, 3.80469212e-10, 2.29943683e-03,\n",
      "       6.42236412e-01, 7.74742523e-03, 6.54561300e-05, 3.80469212e-10,\n",
      "       4.05361690e-03, 3.92787100e-04, 2.00519385e-03, 5.85305042e-06,\n",
      "       4.75385971e-03, 1.80942902e-06, 3.94708849e-03, 2.00339156e-04,\n",
      "       9.55170195e-04, 1.01882463e-07, 3.49936512e-04, 4.41282243e-03,\n",
      "       2.46977806e-03, 4.07001795e-03, 7.38417078e-03, 2.69491249e-03,\n",
      "       1.30441680e-04, 1.53947083e-04, 7.95673754e-04, 2.19790684e-03,\n",
      "       8.54568789e-04, 8.33071768e-04, 2.99719453e-04, 1.11470800e-02,\n",
      "       3.10425705e-04, 3.82331695e-04, 8.56257696e-03, 4.14337497e-03,\n",
      "       1.19857126e-04, 3.51066031e-02, 8.41587968e-03, 6.43156236e-04,\n",
      "       5.31237638e-05, 2.24196527e-04, 4.44333721e-03, 8.93766082e-06,\n",
      "       8.47236788e-06, 1.66865182e-03, 2.93978490e-03, 2.46654242e-01,\n",
      "       1.89290455e-04, 4.37627430e-04, 4.06146375e-03, 4.58605427e-05,\n",
      "       4.46058577e-03, 3.56715941e-03, 3.98114134e-05, 1.51802516e-02,\n",
      "       3.32898402e-04, 2.21542921e-03, 5.36648743e-03, 2.96066974e-05,\n",
      "       1.87756177e-02, 1.30076543e-04, 2.17287522e-02, 5.44028881e-04,\n",
      "       2.18871020e-04, 3.80469212e-10, 1.25927190e-05, 9.95274982e-04,\n",
      "       1.56456139e-03, 7.19421543e-03, 5.85999573e-04, 5.86825889e-04,\n",
      "       3.80514568e-04, 2.23253723e-04, 4.48653795e-04, 1.71756219e-05,\n",
      "       9.23188281e-07, 6.25249743e-02, 7.71760475e-04, 3.02820117e-05,\n",
      "       2.62550917e-03, 2.40066508e-03, 4.19790877e-06, 3.80469212e-10,\n",
      "       2.93031684e-03, 6.19097799e-02, 4.15726739e-04, 1.52487662e-02,\n",
      "       1.44808348e-02, 1.17195062e-02, 1.11895439e-03, 4.79665808e-02,\n",
      "       1.31049301e-05, 6.78251536e-06, 1.26417750e-03, 1.90183264e-03,\n",
      "       3.43738466e-05, 1.59692299e-02, 8.01778297e-05, 5.09900739e-04,\n",
      "       2.97201872e-02, 2.74803746e-03, 7.41733937e-04, 1.86890177e-02,\n",
      "       6.30722893e-03, 2.27850280e-03, 2.27117678e-03, 5.81173990e-05,\n",
      "       3.93395167e-05, 2.12839368e-05, 2.76593375e-04, 2.66838015e-05,\n",
      "       3.66249471e-03, 3.75988916e-03, 9.54714324e-06, 3.80469212e-10,\n",
      "       2.06931672e-05, 3.49070062e-03, 1.28244748e-03, 8.87230544e-06,\n",
      "       9.08871833e-03, 4.09852219e-04, 7.41478754e-03, 3.67001776e-05,\n",
      "       4.79283789e-03, 1.23292487e-03, 6.59109838e-03, 5.84752452e-05,\n",
      "       5.44196064e-06, 1.34100318e-02, 1.19025288e-02, 6.42297743e-03,\n",
      "       5.20538073e-03, 9.61348065e-04, 7.82071656e-05, 1.44153582e-05,\n",
      "       4.56751150e-04, 1.75471519e-04, 1.91561071e-07, 1.26864773e-03,\n",
      "       8.39032291e-04, 6.05597743e-04, 1.04678307e-04, 2.31610075e-01,\n",
      "       2.15287250e-03, 3.63628147e-03, 5.46606071e-03, 3.06096888e-04,\n",
      "       2.68037344e-04, 1.27101282e-03, 9.10338655e-04, 1.60041898e-02],\n",
      "      dtype=float32)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) tf.reduce_sum((GAMMA * next_state_vals - action_vals) ** 2)\n",
      "<tf.Tensor: id=54301171, shape=(), dtype=float32, numpy=2.4722507>\n",
      "(Pdb) tf.reduce_sum((GAMMA * next_state_vals - action_vals) ** 2) / batch_size\n",
      "<tf.Tensor: id=54301181, shape=(), dtype=float32, numpy=0.009657229>\n",
      "(Pdb) val_loss\n",
      "<tf.Tensor: id=54301152, shape=(), dtype=float32, numpy=3.931068e-05>\n",
      "(Pdb) 0.009657229 / batch_size\n",
      "3.772355078125e-05\n",
      "(Pdb) tf.reduce_sum(rewards + GAMMA * next_state_vals * (1-terminals) - action_vals)**2)\n",
      "*** SyntaxError: invalid syntax\n",
      "(Pdb) tf.reduce_sum((rewards + GAMMA * next_state_vals * (1-terminals) - action_vals)**2)\n",
      "<tf.Tensor: id=54301194, shape=(), dtype=float32, numpy=2.5762646>\n",
      "(Pdb) tf.reduce_mean((rewards + GAMMA * next_state_vals * (1-terminals) - action_vals)**2)\n",
      "<tf.Tensor: id=54301206, shape=(), dtype=float32, numpy=0.010063534>\n",
      "(Pdb) rewards + GAMMA * next_state_vals * (1-terminals)\n",
      "<tf.Tensor: id=54301213, shape=(256,), dtype=float32, numpy=\n",
      "array([ 0.20745519,  0.11025237, -0.34454817,  0.26470044, -0.30111846,\n",
      "       -0.6271183 ,  0.56020004,  0.1138127 ,  0.2394736 ,  0.10518594,\n",
      "        0.22777715, -0.1051078 ,  0.33984742,  0.4194074 ,  0.21059106,\n",
      "       -0.03329086,  0.09714093,  0.2149853 ,  0.31714457, -1.        ,\n",
      "        0.878434  ,  0.07575127,  0.02465224,  0.5532976 ,  0.04156369,\n",
      "        0.10098534,  0.24740832,  0.11603767,  0.03031326,  0.16745774,\n",
      "        0.06302807,  0.30845505, -0.09500552,  0.00654973,  0.06832037,\n",
      "        0.35559845, -0.03323777,  0.11025237,  0.19075267,  0.13605106,\n",
      "        0.08747997,  0.01884105,  0.14338508,  0.12004112,  0.24854311,\n",
      "        0.11892448, -0.0575255 ,  0.6612916 ,  0.23722856,  0.10854314,\n",
      "        0.2736529 ,  0.16054665,  0.10527515,  0.14309652,  0.28376704,\n",
      "        0.20699456,  0.22737713,  0.23415309,  0.37500012,  0.23838489,\n",
      "        1.        ,  0.7025045 ,  0.45911103,  0.32009408,  0.07772615,\n",
      "        0.27368993,  0.22468449,  0.15784697,  0.35222304, -0.58247036,\n",
      "        0.7096633 ,  0.2461402 ,  1.        ,  0.29727465, -0.25772873,\n",
      "       -0.26353505,  0.24079287,  0.63389874,  0.12570792,  0.03947314,\n",
      "        0.09137815,  0.25743845,  0.2055776 ,  0.4312821 ,  0.08789245,\n",
      "        0.38476777,  0.17740288,  0.09249   ,  0.30385157,  0.14746127,\n",
      "       -0.04630053, -0.01114165,  0.15893634,  0.2749525 ,  1.        ,\n",
      "        0.21660982, -0.18304911,  0.10959178,  0.01540269,  0.1222733 ,\n",
      "        0.529654  , -0.08822415,  0.07064003, -0.07348446,  0.18117337,\n",
      "        0.09885521,  0.10002665,  0.25563905,  0.10150166,  0.23052377,\n",
      "       -0.5498336 ,  0.10002665, -0.01840897,  0.2026149 ,  0.2502913 ,\n",
      "        0.09719475,  0.18954998,  0.11094841, -0.5724961 ,  0.07152977,\n",
      "        0.13239451,  0.06146542,  0.12501888,  0.17480318, -0.45549518,\n",
      "        0.1212297 ,  0.04548083,  0.7325919 ,  0.11710685,  0.5312189 ,\n",
      "        0.38885558,  0.01333062,  0.34273645,  0.15323927,  0.13666797,\n",
      "       -0.00273724, -0.07129224,  0.5723085 ,  0.03027778,  0.4572331 ,\n",
      "        0.14587642,  0.81619966,  0.5508105 ,  0.627136  ,  0.20643912,\n",
      "        0.32124096,  0.07629241,  0.02048505,  0.13900055,  0.16457793,\n",
      "        0.5724629 , -0.76015604,  0.20782645,  0.05974793,  0.3915144 ,\n",
      "       -0.3232607 ,  0.02585222,  0.55680865,  1.        ,  0.11492594,\n",
      "        0.16663834,  0.10338325,  0.24324927,  0.21339417,  0.20974259,\n",
      "        0.34206024, -0.06543878,  0.06918423,  0.35805973,  0.10002665,\n",
      "        0.78265655,  0.17729206,  0.30908236,  0.7633684 ,  0.11603645,\n",
      "        0.2958389 ,  0.31230414,  0.17162801,  0.12881744,  0.1142345 ,\n",
      "        0.4836226 , -0.09794022,  0.15838003,  0.2240735 ,  0.11688962,\n",
      "        0.25561497,  0.27751157,  0.10002665,  0.21837418, -0.06513062,\n",
      "        0.07961777,  0.5757374 ,  0.12979108,  0.3891456 ,  0.04974072,\n",
      "        0.53611845,  0.07961777,  0.01447908, -0.00738481,  0.19885853,\n",
      "        0.4213767 ,  0.529776  , -0.00313013,  0.23478952,  0.19254558,\n",
      "       -0.11541376,  0.21517934,  0.565855  ,  0.65016145, -0.35891742,\n",
      "        0.4894731 , -0.02000309,  0.11741285,  0.10965349,  0.1222733 ,\n",
      "        0.1465322 ,  0.19520669,  0.12399026,  0.10040758,  0.10002665,\n",
      "        0.12171843,  0.27393496,  0.11360049,  0.03676709, -0.12327605,\n",
      "        0.24496442,  0.6219384 ,  0.18009427,  0.16818453,  0.13953991,\n",
      "        0.2832307 ,  0.11253567,  0.03060689,  0.28283966,  0.08953784,\n",
      "        0.28341088, -0.5724961 ,  0.14177227, -0.5532606 ,  0.28120768,\n",
      "        0.17819652,  0.36382544,  0.10521377,  0.19137643,  0.2016829 ,\n",
      "        0.07470202,  0.15204427,  0.7391969 , -0.57579213,  0.2012537 ,\n",
      "       -0.05394908,  0.10838746,  0.16579345,  0.22130343,  0.10918111,\n",
      "        0.09109665], dtype=float32)>\n",
      "(Pdb) mean_squared_error\n",
      "<tensorflow.python.keras.losses.MeanSquaredError object at 0x116204470>\n",
      "(Pdb) mean_squared_error.reduction\n",
      "'sum'\n",
      "(Pdb) action_vals\n",
      "<tf.Tensor: id=54301137, shape=(256,), dtype=float32, numpy=\n",
      "array([ 0.23295464,  0.10608769, -0.46541274,  0.26060253, -0.32633367,\n",
      "       -0.6475986 ,  0.5910448 ,  0.11418604,  0.26244617, -0.02286929,\n",
      "        0.2118556 , -0.12185896,  0.41840294,  0.3938954 ,  0.2297037 ,\n",
      "       -0.02730406,  0.08402704,  0.28200564,  0.33315122, -0.67885226,\n",
      "        0.7317909 , -0.07371216, -0.14102231,  0.4067698 ,  0.04795732,\n",
      "        0.11669201,  0.1936084 ,  0.13636684,  0.06217175,  0.14931016,\n",
      "        0.06281142,  0.2339678 , -0.05838505,  0.04984601,  0.07038534,\n",
      "        0.28784567, -0.04144522,  0.11114073,  0.14275236,  0.18047272,\n",
      "        0.10000715,  0.06739979,  0.1698161 ,  0.14109714,  0.09591134,\n",
      "        0.1081852 ,  0.04533168,  0.19616799,  0.20671469,  0.03058474,\n",
      "        0.24434859,  0.11394002,  0.10442688,  0.10105338,  0.35625055,\n",
      "        0.22163105,  0.2719112 ,  0.25719017,  0.22086684,  0.22881521,\n",
      "        0.88382196,  0.6891453 ,  0.37761632,  0.24514532,  0.10000715,\n",
      "        0.31034687,  0.14573228,  0.12584214,  0.40604457, -0.63479656,\n",
      "        0.7486172 ,  0.19084652,  0.9792808 ,  0.32455644, -0.21701027,\n",
      "       -0.23970622,  0.44861   ,  0.51514345,  0.13181005,  0.03426949,\n",
      "        0.14338306,  0.2715096 ,  0.23072794,  0.4219157 ,  0.10000715,\n",
      "        0.3383448 ,  0.2092072 ,  0.09344002,  0.31606853,  0.14982393,\n",
      "        0.07722609,  0.02746969,  0.12255901,  0.16333549,  0.75910854,\n",
      "        0.20866829, -0.23018621,  0.12090125,  0.02099658,  0.1389044 ,\n",
      "        0.5537278 , -0.11159476,  0.0725361 ,  0.05862212,  0.1595547 ,\n",
      "        0.10128079,  0.10000715,  0.3035915 , -0.6998949 ,  0.31854323,\n",
      "       -0.5579241 ,  0.10000715,  0.04525905,  0.18279605,  0.2055119 ,\n",
      "        0.09477544,  0.25849822,  0.11229356, -0.635322  ,  0.08568389,\n",
      "        0.16330034,  0.06114623,  0.10631229,  0.24123226, -0.50519204,\n",
      "        0.18502639, -0.04045036,  0.7845045 ,  0.10568575,  0.51881135,\n",
      "        0.41706327,  0.06021246,  0.31350344,  0.12437628,  0.15398037,\n",
      "       -0.10831697, -0.08891114,  0.5918618 , -0.06225641,  0.52160215,\n",
      "        0.15682435,  0.6288321 ,  0.4590724 ,  0.60177547,  0.19915052,\n",
      "        0.30626777,  0.14295077,  0.01749546,  0.14191128,  0.20542707,\n",
      "        0.6266827 , -0.26351306,  0.22158474,  0.08066748,  0.32778478,\n",
      "       -0.31648865,  0.09263984,  0.61653435,  0.8317993 , -0.00828223,\n",
      "        0.18488385,  0.0563149 ,  0.31650558,  0.20795296,  0.34676674,\n",
      "        0.33065513,  0.08196799,  0.0458598 ,  0.37285402,  0.10000715,\n",
      "        0.7791079 ,  0.14574409,  0.3486369 ,  0.84818715,  0.09182902,\n",
      "        0.2716144 ,  0.29279736,  0.18656969,  0.10763599,  0.11009015,\n",
      "        0.48458344, -0.34799019,  0.18616061,  0.22957641,  0.16812934,\n",
      "        0.20661838,  0.2754627 ,  0.10000715,  0.16424178,  0.18368614,\n",
      "        0.10000715,  0.45225152,  0.00945474,  0.49740228,  0.08319149,\n",
      "        0.7551312 ,  0.0759977 ,  0.01708341,  0.02817046,  0.15524852,\n",
      "        0.41551378,  0.40340656,  0.00582408,  0.2573705 ,  0.02015014,\n",
      "       -0.16783549,  0.24241413,  0.42914724,  0.7295795 , -0.40665108,\n",
      "        0.44181624, -0.01237961,  0.11114073,  0.11426694,  0.1389044 ,\n",
      "        0.14136656,  0.25572523,  0.06267232,  0.10349742,  0.10000715,\n",
      "        0.1262674 ,  0.21485281,  0.14941177,  0.03378845, -0.02794128,\n",
      "        0.26520923,  0.53582925,  0.1740362 ,  0.09895421,  0.10442688,\n",
      "        0.36441627,  0.12018258,  0.02827409,  0.16703796,  0.19863655,\n",
      "        0.2032674 , -0.64464444,  0.11076666, -0.54441714,  0.28500444,\n",
      "        0.15682478,  0.35057887,  0.10565145,  0.22699451,  0.23064895,\n",
      "        0.09931091,  0.16227551,  0.25793806, -0.6221912 ,  0.26155528,\n",
      "        0.01998373,  0.12588309,  0.1821653 ,  0.2569547 ,  0.13935293,\n",
      "       -0.03541103], dtype=float32)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) list 17\n",
      " 12  \t\n",
      " 13  \t    with tf.GradientTape() as tape:\n",
      " 14  \t        move_vals = feed_forward(states, dqn)\n",
      " 15  \t        action_vals = get_value_for_action(move_vals, actions)\n",
      " 16  \t        val_loss = mean_squared_error(rewards + GAMMA * next_state_vals * (1-terminals), action_vals) / batch_size\n",
      " 17  ->\t        import pdb; pdb.set_trace()\n",
      " 18  \t\n",
      " 19  \t    metrics['loss'](val_loss)\n",
      " 20  \t\n",
      " 21  \t    # compute and apply gradients\n",
      " 22  \t    gradients = tape.gradient(val_loss, dqn.trainable_variables)\n",
      "(Pdb) mean_squared_error([0., 0., 1., 1.], [1., 1., 1., 0.])\n",
      "<tf.Tensor: id=54301224, shape=(), dtype=float32, numpy=0.75>\n",
      "(Pdb) val_loss * batch_size\n",
      "<tf.Tensor: id=54301227, shape=(), dtype=float32, numpy=0.010063534>\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-9c6b8da3d5bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     num_steps, won = play_a_game(episode, train=True, \n\u001b[1;32m     18\u001b[0m                       \u001b[0mblack_epsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPSILON\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                       white_epsilon=1)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Update exploration/exploitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-78c3705a4638>\u001b[0m in \u001b[0;36mplay_a_game\u001b[0;34m(episode, train, black_epsilon, white_epsilon)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Update the critic and then actor if we are training and have enough events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_mem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mupdate_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mMAX_STEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-ea10f57bc4fc>\u001b[0m in \u001b[0;36mupdate_dqn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0maction_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_value_for_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnext_state_vals\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterminals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_vals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m     \u001b[0;34m\"\"\"Exits the recording context, no further operations are traced.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_call\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(NUM_EPISODES)):\n",
    "    # Reset all metrics\n",
    "    for metric in metrics.values():\n",
    "        metric.reset_states()\n",
    "        \n",
    "    # Update other models if appropriate\n",
    "    dqn.save_weights('tmp/dqn.h5')\n",
    "    if episode % OPPONENT_UPDATE == 0:\n",
    "        opponent.load_weights('tmp/dqn.h5')\n",
    "        logging.debug(\"Updated opponent\")\n",
    "        \n",
    "    if episode % TARGET_UPDATE == 0:\n",
    "        target_policy.load_weights('tmp/dqn.h5')\n",
    "        logging.debug(\"Updated policy\")\n",
    "        \n",
    "    # Train\n",
    "    num_steps, won = play_a_game(episode, train=True, \n",
    "                      black_epsilon=EPSILON, \n",
    "                      white_epsilon=1)\n",
    "    \n",
    "    # Update exploration/exploitation\n",
    "    if EPSILON > EPSILON_MIN:\n",
    "        EPSILON *= EPSILON_DECAY\n",
    "        logging.debug(\"Epsilon decayed to {}\".format(EPSILON))\n",
    "    \n",
    "    # Plot samples of states and response heatmaps\n",
    "    fig = sample_heatmaps()\n",
    "    \n",
    "    # log results\n",
    "    with summary_writers['train'].as_default():\n",
    "        tf.summary.image(\"model heat maps\", plot_to_image(fig), step=episode)\n",
    "        \n",
    "        tf.summary.scalar('won', won, step=episode)\n",
    "        tf.summary.scalar('number of moves', num_steps, step=episode)\n",
    "        tf.summary.scalar('loss', metrics['loss'].result(), step=episode)\n",
    "        tf.summary.scalar('epsilon', EPSILON, step=episode)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights('tmp/dqn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyMNxMAWwJR_"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get win percentage from 100 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_against_random_opponent():\n",
    "    wins = []\n",
    "    for _ in tqdm(range(100)):\n",
    "        num_moves, win = play_a_game(episode=None, \n",
    "                                         train=False, \n",
    "                                         black_epsilon=0, \n",
    "                                         white_epsilon=1)\n",
    "        wins.append(win)\n",
    "    return np.average(wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:39<00:00,  1.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_against_random_opponent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test against a pretrained AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play against our AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97j_uYY9wJSA",
    "outputId": "4d6aa1e6-8b63-4a39-b600-e331284ad6ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "go_env = gym.make('gym_go:go-v0', size='S')\n",
    "\n",
    "state = go_env.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    go_env.render()\n",
    "    \n",
    "    # Actor's move\n",
    "    action = get_action(dqn, state, epsilon=0)\n",
    "    \n",
    "    state, reward, done, info = go_env.step(action)\n",
    "    \n",
    "    go_env.render()\n",
    "    \n",
    "    # Player's move\n",
    "    player_moved = False\n",
    "    while not player_moved:\n",
    "        coords = input(\"Enter coordinates separated by space (`q` to quit)\\n\")\n",
    "        if coords == 'q':\n",
    "            done = True\n",
    "            break\n",
    "        coords = coords.split()\n",
    "        try:\n",
    "            row = int(coords[0])\n",
    "            col = int(coords[1])\n",
    "            print(row, col)\n",
    "            state, reward, done, info = go_env.step((row, col))\n",
    "            player_moved = True\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "go_ai.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
